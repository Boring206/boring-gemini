# Copyright 2026 Boring for Gemini Authors
# SPDX-License-Identifier: Apache-2.0
"""
Vibe Coder Pro Tools - è®“ Vibe Coder ç¨‹å¼ç¢¼é”åˆ°å·¥ç¨‹å¸«æ°´æº–ã€‚

åŒ…å«:
- boring_test_gen: è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ (æ”¯æ´å¤šèªè¨€) + RAG é¢¨æ ¼åƒè€ƒ
- boring_code_review: AI ç¨‹å¼ç¢¼å¯©æŸ¥ (æ”¯æ´å¤šèªè¨€) + BrainManager Pattern æ•´åˆ
- boring_vibe_check: éŠæˆ²åŒ–å¥æª¢ (æ•´åˆ Lint, Security, Doc) + Storage æ­·å²è¿½è¹¤
- boring_impact_check: è¡æ“Šåˆ†æ (å¤šå±¤ä¾è³´è¿½è¹¤) + RAG èªç¾©åˆ†æ

V10.21 æ•´åˆ:
- BrainManager: åƒè€ƒå·²å­¸ç¿’çš„ Pattern é€²è¡Œå¯©æŸ¥
- RAG: èªç¾©æœå°‹ç¾æœ‰æ¸¬è©¦é¢¨æ ¼ã€ä¾è³´åˆ†æ
- Storage: è¨˜éŒ„ Vibe Score æ­·å²è¶¨å‹¢
"""

from pathlib import Path
from typing import Annotated, Optional

from pydantic import Field

from ..security import SecurityScanner  # Phase 14 Enhancement
from ..vibe.engine import VibeEngine
from ..vibe.handlers.generic import GenericHandler
from ..vibe.handlers.javascript import JavascriptHandler
from ..vibe.handlers.python import PythonHandler

# Initialize Engine
vibe_engine = VibeEngine()
vibe_engine.register_handler(PythonHandler())
vibe_engine.register_handler(JavascriptHandler())
vibe_engine.register_handler(GenericHandler())


# =============================================================================
# Boring Core Integration Helpers (V10.21)
# =============================================================================
def _get_brain_manager(project_root: Path):
    """Get BrainManager instance for pattern retrieval."""
    try:
        from ..brain_manager import BrainManager

        return BrainManager(project_root)
    except Exception:
        return None


def _get_storage(project_root: Path):
    """Get SQLiteStorage instance for metrics recording."""
    try:
        from ..storage import SQLiteStorage

        memory_dir = project_root / ".boring_memory"
        # SQLiteStorage.__init__ already creates directories automatically
        # But we add an explicit check here for clarity
        storage = SQLiteStorage(memory_dir)
        return storage
    except ImportError:
        # Missing dependency (unlikely, but possible)
        return None
    except Exception as e:
        # Any other initialization error (permissions, disk space, etc.)
        # Log to stderr for debugging, but don't crash the tool
        import sys

        sys.stderr.write(f"[boring] Warning: Failed to initialize Storage: {e}\n")
        return None


def _get_rag_retriever(project_root: Path):
    """Get RAGRetriever instance for semantic search."""
    try:
        from ..rag.rag_retriever import RAGRetriever

        retriever = RAGRetriever(project_root)
        if retriever.is_available:
            return retriever
    except Exception:
        pass
    return None


def register_vibe_tools(mcp, audited, helpers):
    """
    Register Vibe Coder Pro tools with the MCP server.
    """
    _get_project_root_or_error = helpers["get_project_root_or_error"]

    # === boring_test_gen ===
    @mcp.tool(
        description="è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ (Auto-generate unit tests). "
        "èªª: 'å¹«æˆ‘å¯«æ¸¬è©¦', 'ç”Ÿæˆ auth.py çš„æ¸¬è©¦', 'Generate tests for api.ts'. "
        "æˆ‘æœƒåˆ†æç¨‹å¼ç¢¼ä¸¦ç”Ÿæˆ pytest/jest æ¸¬è©¦æ¡ˆä¾‹ï¼æ”¯æ´ Python, JS, TS. "
        "ğŸ†• V10.21: æ•´åˆ RAG åƒè€ƒç¾æœ‰æ¸¬è©¦é¢¨æ ¼ï¼",
        annotations={"readOnlyHint": False, "openWorldHint": False, "idempotentHint": False},
    )
    @audited
    def boring_test_gen(
        file_path: Annotated[str, Field(description="è¦ç”Ÿæˆæ¸¬è©¦çš„æª”æ¡ˆè·¯å¾‘ (ç›¸å°æˆ–çµ•å°)")],
        output_dir: Annotated[
            Optional[str], Field(description="æ¸¬è©¦è¼¸å‡ºç›®éŒ„ (é è¨­: tests/unit/ æˆ– tests/)")
        ] = None,
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
    ) -> dict:
        """
        ğŸ§ª è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ - åˆ†ææª”æ¡ˆä¸¦ç”Ÿæˆå»ºè­°æ¸¬è©¦ç¨‹å¼ç¢¼ã€‚
        æ”¯æ´å¹³å°: Python (pytest), JavaScript/TypeScript (jest/vitest)

        V10.21 æ•´åˆ:
        - RAG æœå°‹ç¾æœ‰æ¸¬è©¦ï¼Œåƒè€ƒå°ˆæ¡ˆæ¸¬è©¦é¢¨æ ¼
        - ç”Ÿæˆä¸€è‡´æ€§æ›´é«˜çš„æ¸¬è©¦ç¨‹å¼ç¢¼
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return error

        # è§£ææª”æ¡ˆè·¯å¾‘
        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return {"status": "ERROR", "message": f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}"}

        try:
            # 1. ä½¿ç”¨ Engine åˆ†æ
            source = target_file.read_text(encoding="utf-8")
            result = vibe_engine.analyze_for_test_gen(str(target_file), source)

            if not result.functions and not result.classes:
                return {
                    "status": "NO_TESTABLE",
                    "message": "ğŸ˜… æ²’æœ‰æ‰¾åˆ°å¯æ¸¬è©¦çš„å°å‡ºå‡½å¼æˆ–é¡åˆ¥",
                    "file": str(target_file),
                }

            # 2. V10.21: RAG æœå°‹ç¾æœ‰æ¸¬è©¦é¢¨æ ¼
            test_style_hints = []
            rag = _get_rag_retriever(project_root)
            if rag:
                try:
                    # æœå°‹ç¾æœ‰æ¸¬è©¦æª”æ¡ˆ
                    existing_tests = rag.retrieve(
                        query=f"test {target_file.stem} pytest unittest",
                        top_k=3,
                        chunk_types=["function"],
                    )
                    if existing_tests:
                        for r in existing_tests[:2]:
                            if "test_" in r.chunk.name.lower():
                                test_style_hints.append(f"# åƒè€ƒç¾æœ‰æ¸¬è©¦: {r.chunk.name}")
                except Exception:
                    pass  # RAG is optional enhancement

            # 3. ç”Ÿæˆæ¸¬è©¦ç¨‹å¼ç¢¼ (with style hints)
            test_code = vibe_engine.generate_test_code(result, str(project_root))

            # Prepend style hints if available
            if test_style_hints:
                style_comment = "\n".join(test_style_hints)
                test_code = f"# V10.21: å·²åƒè€ƒç¾æœ‰æ¸¬è©¦é¢¨æ ¼\n{style_comment}\n\n{test_code}"

            # 4. æ±ºå®šè¼¸å‡ºè·¯å¾‘
            if output_dir:
                test_dir = project_root / output_dir
            else:
                # è‡ªå‹•åˆ¤æ–·é è¨­ç›®éŒ„
                if result.source_language == "python":
                    test_dir = project_root / "tests" / "unit"
                else:
                    test_dir = project_root / "tests"

            test_dir.mkdir(parents=True, exist_ok=True)
            test_filename = (
                f"test_{target_file.stem}.py"
                if result.source_language == "python"
                else f"{target_file.stem}.test{target_file.suffix}"
            )
            test_file = test_dir / test_filename

            # 5. å¯«å…¥æ¸¬è©¦æª”æ¡ˆ
            test_file.write_text(test_code, encoding="utf-8")

            rag_status = "âœ… RAG é¢¨æ ¼åƒè€ƒ" if test_style_hints else "âš ï¸ RAG æœªå•Ÿç”¨"

            return {
                "status": "SUCCESS",
                "message": f"âœ… å·²ç”Ÿæˆ {result.source_language} æ¸¬è©¦ï¼",
                "test_file": str(test_file),
                "functions_count": len(result.functions),
                "classes_count": len(result.classes),
                "rag_enhanced": bool(test_style_hints),
                "vibe_summary": f"ğŸ§ª ç‚º `{target_file.name}` ç”Ÿæˆäº† {len(result.functions)} å€‹æ¸¬è©¦\n"
                f"ğŸ“ æ¸¬è©¦æª”æ¡ˆ: `{test_file.relative_to(project_root)}`\n"
                f"ğŸŒ èªè¨€: {result.source_language}\n"
                f"ğŸ”— {rag_status}",
            }

        except ValueError as e:
            return {
                "status": "ERROR",
                "message": f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {target_file.suffix}",
                "detail": str(e),
            }
        except Exception as e:
            return {"status": "ERROR", "message": f"âŒ åˆ†æå¤±æ•—: {str(e)}"}

    # === boring_code_review ===
    @mcp.tool(
        description="AI ç¨‹å¼ç¢¼å¯©æŸ¥ (AI Code Review). "
        "èªª: 'å¯©æŸ¥æˆ‘çš„ç¨‹å¼ç¢¼', 'Review my code', 'å¹«æˆ‘çœ‹çœ‹å“ªè£¡å¯ä»¥æ”¹é€²'. "
        "æˆ‘æœƒåˆ†æç¨‹å¼ç¢¼å“è³ªä¸¦çµ¦å‡ºæ”¹å–„å»ºè­°ï¼æ”¯æ´ Python, JS, TS. "
        "ğŸ†• V10.21: æ•´åˆ BrainManager åƒè€ƒå·²å­¸ç¿’çš„ Patternï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_code_review(
        file_path: Annotated[str, Field(description="è¦å¯©æŸ¥çš„æª”æ¡ˆè·¯å¾‘")],
        focus: Annotated[
            Optional[str],
            Field(
                description="å¯©æŸ¥é‡é»: 'all', 'naming', 'error_handling', 'performance', 'security'"
            ),
        ] = "all",
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
    ) -> dict:
        """
        ğŸ” AI ç¨‹å¼ç¢¼å¯©æŸ¥ - åˆ†æç¨‹å¼ç¢¼å“è³ªä¸¦çµ¦å‡ºæ”¹å–„å»ºè­°ã€‚
        æ”¯æ´å¹³å°: Python, JavaScript, TypeScript

        V10.21 æ•´åˆ:
        - BrainManager: åƒè€ƒå°ˆæ¡ˆå·²å­¸ç¿’çš„ Patternï¼Œå¯©æŸ¥æ›´ç²¾æº–
        - æ­·å²éŒ¯èª¤æ¨¡å¼: è­˜åˆ¥æ›¾ç¶“çŠ¯éçš„éŒ¯èª¤
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return error

        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return {"status": "ERROR", "message": f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}"}

        try:
            source = target_file.read_text(encoding="utf-8")
            result = vibe_engine.perform_code_review(str(target_file), source, focus)

            # V10.21: BrainManager æ•´åˆ - å–å¾—ç›¸é—œ Pattern
            brain_patterns = []
            brain = _get_brain_manager(project_root)
            if brain:
                try:
                    # æœå°‹èˆ‡å¯©æŸ¥ç›¸é—œçš„ Pattern
                    patterns = brain.get_relevant_patterns(
                        context=f"{focus} review {target_file.name}", limit=3
                    )
                    for p in patterns:
                        if p.get("pattern_type") in ["code_style", "error_solution", "code_fix"]:
                            brain_patterns.append(
                                {
                                    "type": p.get("pattern_type"),
                                    "description": p.get("description", "")[:100],
                                    "suggestion": p.get("solution", "")[:150],
                                }
                            )
                except Exception:
                    pass  # BrainManager is optional enhancement

            if not result.issues:
                brain_status = (
                    f"\nğŸ§  å·²åƒè€ƒ {len(brain_patterns)} å€‹å°ˆæ¡ˆ Pattern" if brain_patterns else ""
                )
                return {
                    "status": "SUCCESS",
                    "message": f"âœ… ç¨‹å¼ç¢¼å“è³ªè‰¯å¥½ï¼æ²’æœ‰ç™¼ç¾æ˜é¡¯å•é¡Œã€‚{brain_status}",
                    "file": str(target_file),
                    "issues_count": 0,
                    "brain_patterns_used": len(brain_patterns),
                }

            # æŒ‰åš´é‡ç¨‹åº¦æ’åº
            result.issues.sort(key=lambda x: {"high": 0, "medium": 1, "low": 2}.get(x.severity, 3))

            summary_lines = [f"ğŸ” Code Review: `{target_file.name}`", ""]
            for i, issue in enumerate(result.issues[:10], 1):
                severity_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                    issue.severity, "âšª"
                )
                summary_lines.append(f"{i}. {severity_icon} **{issue.category}**: {issue.message}")
                if issue.suggestion:
                    summary_lines.append(f"   ğŸ’¡ å»ºè­°: {issue.suggestion}")

            # V10.21: åŠ å…¥ Brain Pattern å»ºè­°
            if brain_patterns:
                summary_lines.append("")
                summary_lines.append("ğŸ§  **å°ˆæ¡ˆ Pattern å»ºè­°**:")
                for bp in brain_patterns[:2]:
                    summary_lines.append(f"   - {bp['description']}: {bp['suggestion']}")

            # Generate Fix Prompt
            fix_prompt = f"Please review `{target_file.name}` and fix the following {len(result.issues)} issues:\n"
            for issue in result.issues:
                fix_prompt += f"- [{issue.severity.upper()}] {issue.category}: {issue.message}\n"
                if issue.suggestion:
                    fix_prompt += f"  (Suggestion: {issue.suggestion})\n"

            # åŠ å…¥ Brain Pattern åˆ° Fix Prompt
            if brain_patterns:
                fix_prompt += "\nğŸ§  Project-specific patterns to follow:\n"
                for bp in brain_patterns:
                    fix_prompt += f"- {bp['description']}: {bp['suggestion']}\n"

            fix_prompt += "\nReturn the fixed specific functions or class code blocks."

            brain_status = "âœ… Brain Pattern æ•´åˆ" if brain_patterns else "âš ï¸ BrainManager æœªå•Ÿç”¨"

            return {
                "status": "SUCCESS",
                "file": str(target_file),
                "issues_count": len(result.issues),
                "brain_patterns_used": len(brain_patterns),
                "brain_enhanced": bool(brain_patterns),
                "issues": [
                    {
                        "category": i.category,
                        "severity": i.severity,
                        "message": i.message,
                        "line": i.line,
                    }
                    for i in result.issues
                ],
                "brain_patterns": brain_patterns,
                "vibe_summary": "\n".join(summary_lines) + f"\n\nğŸ”— {brain_status}",
                "suggested_fix_prompt": fix_prompt,
            }

        except ValueError:
            return {"status": "ERROR", "message": f"âŒ ä¸æ”¯æ´çš„æ ¼å¼: {target_file.suffix}"}
        except Exception as e:
            return {"status": "ERROR", "message": f"âŒ å¯©æŸ¥å¤±æ•—: {str(e)}"}

    # === boring_perf_tips ===
    @mcp.tool(
        description="æ•ˆèƒ½åˆ†ææç¤º (Performance Tips). "
        "èªª: 'åˆ†ææ•ˆèƒ½', 'æ•ˆèƒ½å„ªåŒ–å»ºè­°', 'Check performance of api.py'. "
        "æˆ‘æœƒå°ˆæ³¨æª¢æŸ¥æ•ˆèƒ½ç“¶é ¸ (å¦‚ N+1 query, I/O in loop) ä¸¦æä¾›å„ªåŒ–å»ºè­°ï¼æ”¯æ´ Py, JS, TS.",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_perf_tips(
        file_path: Annotated[str, Field(description="è¦åˆ†æçš„æª”æ¡ˆè·¯å¾‘")],
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
    ) -> dict:
        """
        âš¡ æ•ˆèƒ½åˆ†ææç¤º - å°ˆæ³¨æ–¼ç¨‹å¼ç¢¼æ•ˆèƒ½ç“¶é ¸æª¢æ¸¬ã€‚
        æ”¯æ´å¹³å°: Python, JavaScript, TypeScript
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return error

        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return {"status": "ERROR", "message": f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}"}

        try:
            source = target_file.read_text(encoding="utf-8")
            # åƒ…å°ˆæ³¨æ–¼ performance
            result = vibe_engine.perform_code_review(str(target_file), source, focus="performance")

            if not result.issues:
                return {
                    "status": "SUCCESS",
                    "message": "âš¡ æ•ˆèƒ½åˆ†æå®Œæˆï¼šæœªç™¼ç¾æ˜é¡¯ç“¶é ¸ã€‚",
                    "file": str(target_file),
                    "tips_count": 0,
                }

            summary_lines = [f"âš¡ Performance Tips: `{target_file.name}`", ""]
            for i, issue in enumerate(result.issues, 1):
                # Performance issues are usually worth highlighting with specific icons
                icon = "ğŸŒ" if issue.severity == "high" else "ğŸ¢"
                summary_lines.append(f"{i}. {icon} **{issue.message}** (Line {issue.line})")
                if issue.suggestion:
                    summary_lines.append(f"   ğŸš€ å„ªåŒ–: {issue.suggestion}")

            # Generate Perf Fix Prompt
            fix_prompt = f"Please analyze performance bottlenecks in `{target_file.name}` and apply the following optimizations:\n"
            for issue in result.issues:
                fix_prompt += f"- {issue.message} (Line {issue.line})\n"
                if issue.suggestion:
                    fix_prompt += f"  Tip: {issue.suggestion}\n"

            return {
                "status": "SUCCESS",
                "file": str(target_file),
                "tips_count": len(result.issues),
                "tips": [
                    {"message": i.message, "line": i.line, "suggestion": i.suggestion}
                    for i in result.issues
                ],
                "vibe_summary": "\n".join(summary_lines),
                "suggested_fix_prompt": fix_prompt,
            }

        except ValueError:
            return {"status": "ERROR", "message": f"âŒ ä¸æ”¯æ´çš„æ ¼å¼: {target_file.suffix}"}
        except Exception as e:
            return {"status": "ERROR", "message": f"âŒ åˆ†æå¤±æ•—: {str(e)}"}

    # === boring_arch_check ===
    @mcp.tool(
        description="æ¶æ§‹åˆ†æ (Architecture Analysis). "
        "èªª: 'åˆ†æå°ˆæ¡ˆæ¶æ§‹', 'Show me the dependencies', 'çœ‹çœ‹èª°å¼•ç”¨èª°', 'è©²å¦‚ä½•é‡æ§‹'. "
        "æˆ‘æœƒç”Ÿæˆ Mermaid ä¾è³´åœ–ï¼Œè®“ä½ ä¸€ç›®äº†ç„¶å°ˆæ¡ˆçµæ§‹ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_arch_check(
        target_path: Annotated[str, Field(description="File or directory to scan.")] = ".",
        output_format: Annotated[
            str, Field(description="Output format: 'mermaid' or 'json'.")
        ] = "mermaid",
    ) -> str:
        """
        Analyze project dependencies and architecture.

        Generates a dependency graph showing how files import each other.
        Use this to understand the structure of a codebase.
        """
        root_str, error = _get_project_root_or_error(
            None
        )  # project_path is now optional and handled by get_root
        if error:
            return error.get("message")

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        files_to_scan = []
        if target.is_file():
            files_to_scan.append(target)
        elif target.is_dir():
            files_to_scan.extend(
                [
                    p
                    for p in target.rglob("*")
                    if p.is_file()
                    and p.suffix.lower() in [".py", ".js", ".ts", ".jsx", ".tsx"]
                    and not any(
                        x in p.parts for x in ["node_modules", ".git", "__pycache__", "venv"]
                    )
                ]
            )
        else:
            return f"âŒ Target not found: {target}"

        edges = []
        nodes = set()

        for file_path in files_to_scan:
            try:
                rel_path = file_path.relative_to(project_root).as_posix()
                content = file_path.read_text(encoding="utf-8", errors="ignore")

                deps = vibe_engine.extract_dependencies(str(file_path), content)

                if deps:
                    nodes.add(rel_path)
                    for dep in deps:
                        # Simple normalization
                        dep_name = dep
                        if dep.startswith("."):
                            # Attempt simple resolve?
                            # For visualization, generic name is arguably better than huge guess
                            pass

                        edge = (rel_path, dep_name)
                        edges.append(edge)
            except Exception:
                continue

        if output_format == "json":
            return str({"nodes": list(nodes), "edges": edges})

        # Mermaid format
        lines = ["graph TD"]
        max_edges = 100

        # Limit edges to avoid explosion
        processed_count = 0
        for src, dst in edges:
            if processed_count >= max_edges:
                lines.append(f"    %% Truncated after {max_edges} edges")
                break

            # Simple sanitization for Mermaid IDs
            def clean_id(s):
                return s.replace("/", "_").replace(".", "_").replace("-", "_").replace("@", "")

            s_id = clean_id(src)
            d_id = clean_id(dst)

            # Add node labels
            lines.append(f'    {s_id}["{src}"] --> {d_id}["{dst}"]')
            processed_count += 1

        return "\n".join(lines)

    # === boring_doc_gen ===
    @mcp.tool(
        description="è‡ªå‹•ç”Ÿæˆæ–‡æª” (Auto-generate Documentation). "
        "èªª: 'å¹«æˆ‘å¯«æ–‡æª”', 'Generate docs for api.py', 'API æ–‡æª”', 'è‡ªå‹•è¨»è§£'. "
        "æˆ‘æœƒæ“·å– Docstrings/JSDoc ä¸¦ç”Ÿæˆ Markdown åƒè€ƒæ–‡æª”ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_doc_gen(
        target_path: Annotated[str, Field(description="File or directory to scan.")] = ".",
    ) -> str:
        """
        Extract documentation comments and generate an API reference.

        Supports:
        - Python Docstrings (Module, Class, Function)
        - JavaScript/TypeScript JSDoc (/** ... */)

        Returns Markdown content.
        """
        root_str, error = _get_project_root_or_error(None)
        if error:
            return error.get("message")

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        files_to_scan = []
        if target.is_file():
            files_to_scan.append(target)
        elif target.is_dir():
            files_to_scan.extend(
                [
                    p
                    for p in target.rglob("*")
                    if p.is_file()
                    and p.suffix.lower() in [".py", ".js", ".ts", ".jsx", ".tsx"]
                    and not any(
                        x in p.parts
                        for x in ["node_modules", ".git", "__pycache__", "venv", "dist", "build"]
                    )
                ]
            )
        else:
            return f"âŒ Target not found: {target}"

        doc_output = [f"# API Documentation\n\nGenerated for: `{target_path}`\n"]

        for file_path in sorted(files_to_scan):
            try:
                content = file_path.read_text(encoding="utf-8", errors="ignore")
                rel_path = file_path.relative_to(project_root).as_posix()

                result = vibe_engine.extract_documentation(str(file_path), content)

                if not result.items and not result.module_doc:
                    continue

                doc_output.append(f"## File: `{rel_path}`\n")
                if result.module_doc:
                    doc_output.append(f"> {result.module_doc.strip()}\n")

                doc_output.append("")

                for item in result.items:
                    icon = "ğŸ“¦" if item.type == "class" else "Æ’"
                    doc_output.append(f"### {icon} `{item.name}`")
                    doc_output.append(f"**Signature:** `{item.signature}`\n")
                    if item.docstring:
                        doc_output.append(f"{item.docstring}\n")
                    else:
                        doc_output.append("*No documentation.*\n")
                    doc_output.append("---\n")

            except Exception as e:
                doc_output.append(f"<!-- Error processing {file_path.name}: {e} -->\n")

        return "\n".join(doc_output)

    # === boring_vibe_check ===
    @mcp.tool(
        description="Vibe Score å¥æª¢ (Gamified Health Check). "
        "èªª: 'Vibe Check my project', 'å¥æª¢ utils.py', 'Give me a vibe score'. "
        "æˆ‘æœƒæ•´åˆ Lint, Security, Doc æª¢æŸ¥ï¼Œè¨ˆç®— 0-100 åˆ†æ•¸ï¼Œä¸¦æä¾›ä¸€éµä¿®å¾© Promptï¼ "
        "ğŸ†• V10.21: æ•´åˆ Storage è¨˜éŒ„æ­·å²åˆ†æ•¸è¶¨å‹¢ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_vibe_check(
        target_path: Annotated[str, Field(description="è¦å¥æª¢çš„æª”æ¡ˆæˆ–ç›®éŒ„")] = ".",
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
        max_files: Annotated[int, Field(description="æœ€å¤§æƒææª”æ¡ˆæ•¸ (é è¨­ 10)")] = 10,
    ) -> dict:
        """
        ğŸ“Š Vibe Check - å…¨é¢å¥åº·åº¦æª¢æŸ¥èˆ‡è©•åˆ†ã€‚
        æ•´åˆå¤šé …æŒ‡æ¨™ (Lint, Security, Doc)ï¼Œæä¾›éŠæˆ²åŒ–è©•åˆ†èˆ‡ä¸€éµä¿®å¾© Promptã€‚

        V10.21 æ•´åˆ:
        - Storage: è¨˜éŒ„ Vibe Score æ­·å²ï¼Œè¿½è¹¤å°ˆæ¡ˆå¥åº·è¶¨å‹¢
        - é¡¯ç¤ºèˆ‡ä¸Šæ¬¡åˆ†æ•¸çš„å°æ¯”
        """
        root_str, error = _get_project_root_or_error(project_path)
        if error:
            return error

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":"):
            # Absolute path (Unix-style or Windows-style)
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            # Relative path
            target = project_root / target_path

        if not target.exists():
            return {"status": "ERROR", "message": f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™: {target}"}

        # 1. æ”¶é›†æª”æ¡ˆ
        files_to_check = []
        if target.is_file():
            files_to_check.append(target)
        else:
            candidates = [
                p
                for p in target.rglob("*")
                if p.is_file()
                and p.suffix in [".py", ".js", ".ts"]
                and not any(x in p.parts for x in ["node_modules", ".git", "venv"])
            ][:max_files]
            files_to_check.extend(candidates)

        if not files_to_check:
            return {"status": "ERROR", "message": "âš ï¸ æ‰¾ä¸åˆ°å¯åˆ†æçš„ç¨‹å¼ç¢¼æª”æ¡ˆ (.py, .js, .ts)"}

        # Scoring Variables
        base_score = 100
        deductions = 0
        issues_found = []
        doc_missing = 0
        security_issues = []

        # 2. é€æª”åˆ†æ
        for f in files_to_check:
            try:
                content = f.read_text(encoding="utf-8", errors="ignore")

                # A. Code Review (Lint/Quality)
                rev_res = vibe_engine.perform_code_review(str(f), content, focus="all")
                for issue in rev_res.issues:
                    deduction = (
                        5 if issue.severity == "low" else 10 if issue.severity == "medium" else 15
                    )
                    deductions += deduction
                    issues_found.append(f"[{f.name}:{issue.line}] {issue.message}")

                # B. Doc Check
                doc_res = vibe_engine.extract_documentation(str(f), content)
                for item in doc_res.items:
                    if not item.docstring:
                        deductions += 5
                        doc_missing += 1

            except Exception:
                continue

        # 3. Security Scan (Phase 14 Enhancement)
        try:
            scanner = SecurityScanner(project_root)
            sec_report = scanner.scan_for_secrets(target if target.is_dir() else target.parent)
            for sec_issue in sec_report.issues:
                severity_deduction = (
                    20
                    if sec_issue.severity == "CRITICAL"
                    else 15
                    if sec_issue.severity == "HIGH"
                    else 10
                )
                deductions += severity_deduction
                security_issues.append(
                    f"ğŸ”’ [{sec_issue.severity}] {sec_issue.description} ({sec_issue.file_path}:{sec_issue.line_number})"
                )
        except Exception:
            pass  # Security scan is optional enhancement

        # 4. è¨ˆç®—åˆ†æ•¸
        final_score = max(0, base_score - deductions)

        # 5. è©•ç´š
        if final_score >= 95:
            tier = "S-Tier (God Like) ğŸ†"
        elif final_score >= 85:
            tier = "A-Tier (Professional) ğŸ¥‡"
        elif final_score >= 75:
            tier = "B-Tier (Solid) ğŸ¥ˆ"
        elif final_score >= 60:
            tier = "C-Tier (Meh) ğŸ¥‰"
        else:
            tier = "F-Tier (Spaghetti) ğŸ"

        # 6. ç”Ÿæˆ One-Click Fix Prompt
        fix_prompt = ""
        if final_score < 100:
            fix_prompt = f"Please act as a Senior Engineer to fix the low Vibe Score ({final_score}) for the following files:\n"
            fix_prompt += f"Target: `{target_path}`\n\n"
            fix_prompt += "Tasks:\n"

            if issues_found:
                fix_prompt += "1. Fix the following code quality issues:\n"
                for i in issues_found[:10]:
                    fix_prompt += f"   - {i}\n"
                if len(issues_found) > 10:
                    fix_prompt += f"   - ... and {len(issues_found) - 10} more issues.\n"

            if doc_missing > 0:
                fix_prompt += f"2. Add missing docstrings/JSDoc to {doc_missing} functions/classes to meet Google Style Guide.\n"

            if security_issues:
                fix_prompt += "3. âš ï¸ CRITICAL: Remove or rotate the following exposed secrets:\n"
                for sec in security_issues[:5]:
                    fix_prompt += f"   - {sec}\n"

            fix_prompt += "\nReturn the corrected code directly."
        else:
            fix_prompt = "ğŸ‰ Perfect Score! No fixes needed. Maybe go touch some grass? ğŸŒ±"

        # 7. V10.21: Storage æ­·å²è¿½è¹¤
        score_trend = ""
        previous_score = None
        storage = _get_storage(project_root)
        if storage:
            try:
                # è¨˜éŒ„æœ¬æ¬¡åˆ†æ•¸
                storage.record_metric(
                    name="vibe_score",
                    value=float(final_score),
                    metadata={
                        "target": target_path,
                        "issues": len(issues_found),
                        "doc_missing": doc_missing,
                        "security_issues": len(security_issues),
                        "tier": tier,
                    },
                )

                # å–å¾—æ­·å²åˆ†æ•¸
                history = storage.get_metrics("vibe_score", limit=5)
                if len(history) > 1:
                    previous_score = history[1].get("metric_value")
                    if previous_score is not None:
                        diff = final_score - previous_score
                        if diff > 0:
                            score_trend = f"ğŸ“ˆ +{diff:.0f} (vs ä¸Šæ¬¡ {previous_score:.0f})"
                        elif diff < 0:
                            score_trend = f"ğŸ“‰ {diff:.0f} (vs ä¸Šæ¬¡ {previous_score:.0f})"
                        else:
                            score_trend = f"â¡ï¸ ç¶­æŒ {previous_score:.0f}"
            except Exception:
                pass  # Storage is optional enhancement

        storage_status = "âœ… åˆ†æ•¸å·²è¨˜éŒ„" if storage else "âš ï¸ Storage æœªå•Ÿç”¨"

        return {
            "status": "SUCCESS",
            "score": final_score,
            "tier": tier,
            "issues_count": len(issues_found),
            "doc_missing_count": doc_missing,
            "security_issues_count": len(security_issues),
            "previous_score": previous_score,
            "score_trend": score_trend,
            "storage_enhanced": storage is not None,
            "vibe_summary": f"ğŸ“Š **Vibe Score**: {final_score} / 100 {score_trend}\n"
            f"ğŸ… **Tier**: {tier}\n"
            f"ğŸ› **Issues**: {len(issues_found)}\n"
            f"ğŸ“ **Missing Docs**: {doc_missing}\n"
            f"ğŸ”’ **Security Issues**: {len(security_issues)}\n"
            f"ğŸ’¾ {storage_status}",
            "suggested_fix_prompt": fix_prompt,
        }

    # === boring_impact_check ===
    @mcp.tool(
        description="è¡æ“Šåˆ†æ (Impact Analysis). "
        "èªª: 'Check impact of modifying utils.py', 'æ”¹é€™éš»æª”æ¡ˆæœƒå½±éŸ¿èª°', 'Impact check'. "
        "æˆ‘æœƒåˆ†æåå‘ä¾è³´ (æ”¯æ´å¤šå±¤è¿½è¹¤)ï¼Œå‘Šè¨´ä½ ä¿®æ”¹æ­¤æª”æ¡ˆæœƒå½±éŸ¿å“ªäº›æ¨¡çµ„ï¼Œä¸¦çµ¦å‡ºé©—è­‰ Promptï¼ "
        "ğŸ†• V10.21: æ•´åˆ RAG èªç¾©åˆ†ææ›´ç²¾æº–ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_impact_check(
        target_path: Annotated[str, Field(description="è¨ˆç•«ä¿®æ”¹çš„ç›®æ¨™æª”æ¡ˆ")],
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
        max_depth: Annotated[
            int, Field(description="è¿½è¹¤æ·±åº¦ (1=ç›´æ¥ä¾è³´, 2=é–“æ¥ä¾è³´, é è¨­ 2)")
        ] = 2,
    ) -> dict:
        """
        ğŸ“¡ Impact Analysis - é åˆ¤ä¿®æ”¹å¸¶ä¾†çš„å…¨å±€è¡æ“Šã€‚
        Reverse Dependency Analysis with multi-level tracking (Phase 15 Enhancement).

        V10.21 æ•´åˆ:
        - RAG èªç¾©æœå°‹: æ‰¾å‡ºèªç¾©ç›¸é—œçš„æª”æ¡ˆï¼ˆä¸åªæ˜¯ importï¼‰
        - æ›´ç²¾æº–çš„è¡æ“Šåˆ†æ
        """
        root_str, error = _get_project_root_or_error(project_path)
        if error:
            return error

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        if not target.exists() or not target.is_file():
            return {"status": "ERROR", "message": f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™æª”æ¡ˆ: {target_path}"}

        # 1. è­˜åˆ¥ç›®æ¨™ç‰¹å¾µ for fuzzy matching
        target_stem = target.stem  # e.g., "utils"
        rel_target = target.relative_to(project_root).as_posix()

        # V10.21: RAG èªç¾©åˆ†æ - æ‰¾å‡ºèªç¾©ç›¸é—œçš„æª”æ¡ˆ
        semantic_related = []
        rag = _get_rag_retriever(project_root)
        if rag:
            try:
                # è®€å–ç›®æ¨™æª”æ¡ˆå…§å®¹ï¼Œæå–é—œéµè©
                target_content = target.read_text(encoding="utf-8", errors="ignore")[:500]

                # èªç¾©æœå°‹ç›¸é—œå‡½æ•¸/é¡åˆ¥
                results = rag.retrieve(
                    query=f"{target_stem} {target_content[:100]}",
                    top_k=5,
                    chunk_types=["function", "class"],
                )
                for r in results:
                    if r.chunk.file_path != str(target):
                        rel_path = Path(r.chunk.file_path).relative_to(project_root).as_posix()
                        if rel_path not in semantic_related:
                            semantic_related.append(rel_path)
            except Exception:
                pass  # RAG is optional enhancement

        # 2. å…¨å°ˆæ¡ˆæƒæå»ºç«‹å®Œæ•´ä¾è³´åœ–
        files_to_scan = [
            p
            for p in project_root.rglob("*")
            if p.is_file()
            and p.suffix in [".py", ".js", ".ts", ".jsx", ".tsx"]
            and not any(
                x in p.parts
                for x in ["node_modules", ".git", "venv", "__pycache__", "dist", "build"]
            )
        ]

        # Build dependency graph: { file_rel_path -> [dependencies] }
        dep_graph = {}
        file_stems = {}  # stem -> [rel_paths]

        for f in files_to_scan:
            try:
                content = f.read_text(encoding="utf-8", errors="ignore")
                deps = vibe_engine.extract_dependencies(str(f), content)
                f_rel = f.relative_to(project_root).as_posix()
                dep_graph[f_rel] = deps

                # Index by stem for fuzzy matching
                stem = f.stem
                if stem not in file_stems:
                    file_stems[stem] = []
                file_stems[stem].append(f_rel)
            except Exception:
                continue

        # 3. Fuzzy matching helper
        def matches_target(dep: str, target_stem: str) -> bool:
            if target_stem == dep:
                return True
            if dep.endswith(f".{target_stem}"):
                return True
            if dep.endswith(f"/{target_stem}"):
                return True
            return False

        # 4. Build reverse dependency graph (who imports what)
        # direct_dependents: files that directly import target
        direct_dependents = set()
        for f_rel, deps in dep_graph.items():
            if f_rel == rel_target:
                continue
            for dep in deps:
                if matches_target(dep, target_stem):
                    direct_dependents.add(f_rel)
                    break

        # 5. Multi-level impact tracking (Phase 15 Enhancement)
        all_affected = set(direct_dependents)
        indirect_dependents = set()

        if max_depth >= 2:
            # Level 2: Find files that import direct_dependents
            for direct_dep in direct_dependents:
                direct_stem = Path(direct_dep).stem
                for f_rel, deps in dep_graph.items():
                    if f_rel in all_affected or f_rel == rel_target:
                        continue
                    for dep in deps:
                        if matches_target(dep, direct_stem):
                            indirect_dependents.add(f_rel)
                            all_affected.add(f_rel)
                            break

        # Level 3 (if max_depth >= 3)
        level3_dependents = set()
        if max_depth >= 3:
            for indirect_dep in indirect_dependents:
                indirect_stem = Path(indirect_dep).stem
                for f_rel, deps in dep_graph.items():
                    if f_rel in all_affected or f_rel == rel_target:
                        continue
                    for dep in deps:
                        if matches_target(dep, indirect_stem):
                            level3_dependents.add(f_rel)
                            all_affected.add(f_rel)
                            break

        # 6. è©•ä¼°è¡æ“Šç­‰ç´š
        impact_level = "Low"
        if len(all_affected) > 10:
            impact_level = "Critical"
        elif len(all_affected) > 5:
            impact_level = "High"
        elif len(all_affected) > 0:
            impact_level = "Medium"

        # 7. Mermaid åœ–å½¢è¼¸å‡º
        mermaid_lines = ["graph TD", f'    Target["{rel_target}"]:::target']

        # Direct impacts
        for imp in list(direct_dependents)[:15]:
            sanitized_imp = imp.replace("/", "_").replace(".", "_").replace("-", "_")
            mermaid_lines.append(f'    {sanitized_imp}["{imp}"]:::direct -->|L1| Target')

        # Indirect impacts
        for imp in list(indirect_dependents)[:10]:
            sanitized_imp = imp.replace("/", "_").replace(".", "_").replace("-", "_")
            mermaid_lines.append(f'    {sanitized_imp}["{imp}"]:::indirect -->|L2| ...')

        mermaid_lines.append("    classDef target fill:#f96,stroke:#333")
        mermaid_lines.append("    classDef direct fill:#ff9,stroke:#333")
        mermaid_lines.append("    classDef indirect fill:#9ff,stroke:#333")
        mermaid_graph = "\n".join(mermaid_lines)

        # 8. Fix/Verification Prompt
        verify_prompt = ""
        if all_affected:
            verify_prompt = (
                f"âš ï¸ Impact Warning: Modifying `{rel_target}` affects {len(all_affected)} files.\n\n"
            )

            if direct_dependents:
                verify_prompt += (
                    f"ğŸ”´ **Direct Dependents (L1)** - {len(direct_dependents)} files:\n"
                )
                for aff in list(direct_dependents)[:5]:
                    verify_prompt += f"   - `{aff}`\n"
                if len(direct_dependents) > 5:
                    verify_prompt += f"   - ... and {len(direct_dependents) - 5} more.\n"

            if indirect_dependents:
                verify_prompt += (
                    f"\nğŸŸ¡ **Indirect Dependents (L2)** - {len(indirect_dependents)} files:\n"
                )
                for aff in list(indirect_dependents)[:5]:
                    verify_prompt += f"   - `{aff}`\n"
                if len(indirect_dependents) > 5:
                    verify_prompt += f"   - ... and {len(indirect_dependents) - 5} more.\n"

            # V10.21: åŠ å…¥ RAG èªç¾©ç›¸é—œæª”æ¡ˆ
            if semantic_related:
                verify_prompt += (
                    f"\nğŸ§  **Semantically Related (RAG)** - {len(semantic_related)} files:\n"
                )
                for sem in semantic_related[:3]:
                    verify_prompt += f"   - `{sem}`\n"

            verify_prompt += (
                "\nğŸ“‹ **Action Required**: Run tests for these files after your changes."
            )
        else:
            verify_prompt = f"âœ… Low Impact: `{rel_target}` appears to have no internal dependents."

        rag_status = (
            f"âœ… RAG èªç¾©åˆ†æ ({len(semantic_related)} ç›¸é—œ)"
            if semantic_related
            else "âš ï¸ RAG æœªå•Ÿç”¨"
        )

        return {
            "status": "SUCCESS",
            "impact_level": impact_level,
            "affected_count": len(all_affected),
            "direct_count": len(direct_dependents),
            "indirect_count": len(indirect_dependents),
            "semantic_related_count": len(semantic_related),
            "rag_enhanced": bool(semantic_related),
            "affected_files": list(all_affected),
            "direct_dependents": list(direct_dependents),
            "indirect_dependents": list(indirect_dependents),
            "semantic_related": semantic_related,
            "mermaid": mermaid_graph,
            "vibe_summary": f"ğŸ“¡ **Impact Analysis**: `{rel_target}`\n"
            f"âš ï¸ **Impact Level**: {impact_level}\n"
            f"ğŸ”— **Direct (L1)**: {len(direct_dependents)}\n"
            f"ğŸ”— **Indirect (L2+)**: {len(indirect_dependents)}\n"
            f"ğŸ§  **Semantic (RAG)**: {len(semantic_related)}\n"
            f"ğŸ”— {rag_status}",
            "suggested_fix_prompt": verify_prompt,
        }

    # =========================================================================
    # V10.22: Intelligence Tools
    # =========================================================================

    @mcp.tool(
        description="ğŸ”® é æ¸¬å¯èƒ½çš„éŒ¯èª¤ (Predict likely errors before running). "
        "èªª: 'é æ¸¬é€™å€‹æª”æ¡ˆæœƒæœ‰ä»€éº¼éŒ¯èª¤', 'predict errors for auth.py'. "
        "æˆ‘æœƒåˆ†ææ­·å²æ¨¡å¼ï¼Œé æ¸¬æœ€å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ä¸¦æä¾›é é˜²å»ºè­°ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_predict_errors(
        file_path: Annotated[str, Field(description="è¦é æ¸¬éŒ¯èª¤çš„æª”æ¡ˆè·¯å¾‘")],
        limit: Annotated[int, Field(description="æœ€å¤šè¿”å›å¹¾å€‹é æ¸¬")] = 5,
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> dict:
        """
        ğŸ”® é æ¸¬éŒ¯èª¤ - æ ¹æ“šæ­·å²æ¨¡å¼é æ¸¬å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ã€‚

        V10.22 Intelligence:
        - åˆ†ææª”æ¡ˆé¡å‹èˆ‡éå»éŒ¯èª¤çš„é—œè¯
        - æä¾›ä¿¡å¿ƒåˆ†æ•¸å’Œé é˜²å»ºè­°
        - å­¸ç¿’å°ˆæ¡ˆç‰¹å®šçš„éŒ¯èª¤æ¨¡å¼
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return error

        # Try to use PredictiveAnalyzer
        predictions = []
        try:
            from ..intelligence import PredictiveAnalyzer

            analyzer = PredictiveAnalyzer(project_root)
            predictions = analyzer.predict_errors(file_path, limit)
        except ImportError:
            pass

        # Fallback to storage-based prediction
        if not predictions:
            storage = _get_storage(project_root)
            if storage:
                predictions_data = storage.get_error_predictions(file_path, limit)
                for p in predictions_data:
                    predictions.append(type("Prediction", (), p)())

        if not predictions:
            return {
                "status": "NO_DATA",
                "message": "ğŸ“Š å°šç„¡è¶³å¤ æ­·å²è³‡æ–™é€²è¡Œé æ¸¬ã€‚ç¹¼çºŒä½¿ç”¨ç³»çµ±ç´¯ç©è³‡æ–™ï¼",
                "file_path": file_path,
            }

        # Format results
        result_items = []
        for p in predictions:
            result_items.append(
                {
                    "error_type": p.error_type
                    if hasattr(p, "error_type")
                    else p.get("error_type", "Unknown"),
                    "confidence": getattr(p, "confidence", p.get("confidence", 0.5)),
                    "message": getattr(p, "predicted_message", p.get("message", "")),
                    "prevention_tip": getattr(p, "prevention_tip", p.get("prevention_tip", "")),
                    "frequency": getattr(p, "historical_frequency", p.get("frequency", 0)),
                }
            )

        # Build summary
        top = result_items[0] if result_items else None
        summary = f"ğŸ”® **Error Predictions for** `{file_path}`\n\n"
        for i, item in enumerate(result_items[:5], 1):
            conf_bar = (
                "ğŸŸ¢" if item["confidence"] >= 0.7 else "ğŸŸ¡" if item["confidence"] >= 0.4 else "âšª"
            )
            summary += f"{i}. {conf_bar} **{item['error_type']}** ({item['confidence'] * 100:.0f}% confidence)\n"
            summary += f"   ğŸ’¡ {item['prevention_tip']}\n"

        return {
            "status": "SUCCESS",
            "predictions": result_items,
            "top_prediction": top,
            "file_path": file_path,
            "vibe_summary": summary,
        }

    @mcp.tool(
        description="ğŸ“Š å°ˆæ¡ˆå¥åº·è©•åˆ† (Project health score). "
        "èªª: 'å°ˆæ¡ˆå¥åº·ç‹€æ³', 'çµ¦æˆ‘å¥åº·å ±å‘Š', 'project health score'. "
        "æˆ‘æœƒåˆ†ææˆåŠŸç‡ã€éŒ¯èª¤è¶¨å‹¢ã€è§£æ±ºç‡ï¼Œçµ¦å‡ºç¶œåˆå¥åº·è©•åˆ†ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_health_score(
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> dict:
        """
        ğŸ“Š å°ˆæ¡ˆå¥åº·è©•åˆ† - ç¶œåˆåˆ†æå°ˆæ¡ˆç‹€æ…‹ã€‚

        V10.22 Intelligence:
        - æˆåŠŸç‡åˆ†æ (40% æ¬Šé‡)
        - éŒ¯èª¤è§£æ±ºç‡ (30% æ¬Šé‡)
        - åŸ·è¡Œæ•ˆç‡ (30% æ¬Šé‡)
        - è¶¨å‹¢åˆ†æå’Œå»ºè­°
        """
        try:
            project_root = _get_project_root_or_error(project_path)
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}

        storage = _get_storage(project_root)
        if not storage:
            return {"status": "ERROR", "message": "Storage æœªåˆå§‹åŒ–"}

        # Get health score
        health = storage.get_health_score()

        # Get error trend
        trend = storage.get_error_trend(days=7)

        # Build detailed report
        score = health["score"]
        grade = health["grade"]

        # Emoji for grade
        grade_emoji = {
            "A+": "ğŸ†",
            "A": "ğŸŒŸ",
            "B": "âœ…",
            "C": "ğŸ‘",
            "D": "âš ï¸",
            "F": "ğŸš¨",
            "N/A": "ğŸ“Š",
        }.get(grade, "ğŸ“Š")

        breakdown = health.get("breakdown", {})

        summary = f"""# {grade_emoji} å°ˆæ¡ˆå¥åº·å ±å‘Š

## ç¶œåˆè©•åˆ†: **{score}/100** (ç­‰ç´š: {grade})

{health["message"]}

## ğŸ“ˆ æŒ‡æ¨™åˆ†è§£
- æˆåŠŸç‡: **{breakdown.get("success_rate", "N/A")}%**
- éŒ¯èª¤è§£æ±ºç‡: **{breakdown.get("resolution_rate", "N/A")}%**
- å¹³å‡åŸ·è¡Œæ™‚é–“: **{breakdown.get("avg_loop_duration", "N/A")}s**

## ğŸ“Š éŒ¯èª¤è¶¨å‹¢ (7å¤©)
- è¶¨å‹¢æ–¹å‘: {trend.get("emoji", "â¡ï¸")} {trend.get("trend", "N/A")}
- è®ŠåŒ–å¹…åº¦: {trend.get("change_percent", 0)}%
- {trend.get("recommendation", "")}
"""

        return {
            "status": "SUCCESS",
            "score": score,
            "grade": grade,
            "health": health,
            "trend": trend,
            "vibe_summary": summary,
        }

    @mcp.tool(
        description="ğŸ§  å„ªåŒ–ä¸Šä¸‹æ–‡ (Optimize context for LLM). "
        "èªª: 'å¹«æˆ‘å£“ç¸®é€™äº›ç¨‹å¼ç¢¼', 'optimize context'. "
        "æˆ‘æœƒæ™ºèƒ½å£“ç¸®ç¨‹å¼ç¢¼ä¸Šä¸‹æ–‡ï¼Œæ¸›å°‘ token ä½¿ç”¨åŒæ™‚ä¿ç•™é—œéµè³‡è¨Šï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_optimize_context(
        file_paths: Annotated[list[str], Field(description="è¦å„ªåŒ–çš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨")],
        max_tokens: Annotated[int, Field(description="æœ€å¤§ token é™åˆ¶")] = 8000,
        error_message: Annotated[
            Optional[str], Field(description="ç›¸é—œéŒ¯èª¤è¨Šæ¯ (æœ€é«˜å„ªå…ˆç´š)")
        ] = None,
        project_path: Annotated[Optional[str], Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> dict:
        """
        ğŸ§  ä¸Šä¸‹æ–‡å„ªåŒ– - æ™ºèƒ½å£“ç¸®ç¨‹å¼ç¢¼ä»¥æ¸›å°‘ token ä½¿ç”¨ã€‚

        V10.22 Intelligence:
        - å»é‡è¤‡å…§å®¹
        - å„ªå…ˆä¿ç•™é—œéµç¨‹å¼ç¢¼
        - å£“ç¸®æ–‡æª”å’Œè¨»é‡‹
        - ä¿æŒèªç¾©å®Œæ•´æ€§
        """
        try:
            project_root = _get_project_root_or_error(project_path)
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}

        try:
            from ..intelligence import SmartContextBuilder

            builder = SmartContextBuilder(max_tokens=max_tokens, project_root=project_root)
        except ImportError:
            return {"status": "ERROR", "message": "Intelligence æ¨¡çµ„æœªå®‰è£"}

        # Add error context (highest priority)
        if error_message:
            builder.with_error(error_message, priority=1.0)

        # Add code files
        for fp in file_paths:
            try:
                path = Path(project_root) / fp if not Path(fp).is_absolute() else Path(fp)
                if path.exists():
                    content = path.read_text(encoding="utf-8", errors="ignore")
                    rel_path = (
                        str(path.relative_to(project_root))
                        if path.is_relative_to(project_root)
                        else str(path)
                    )
                    builder.with_code_file(rel_path, content, priority=0.8)
            except Exception:
                continue

        # Build optimized context
        optimized = builder.build()
        report = builder.get_compression_report()
        stats = builder.stats

        return {
            "status": "SUCCESS",
            "optimized_context": optimized,
            "stats": {
                "original_tokens": stats.original_tokens if stats else 0,
                "optimized_tokens": stats.optimized_tokens if stats else 0,
                "compression_ratio": stats.compression_ratio if stats else 1.0,
                "sections_removed": stats.sections_removed if stats else 0,
                "duplicates_merged": stats.duplicates_merged if stats else 0,
            },
            "vibe_summary": report,
        }

    return {
        "boring_test_gen": boring_test_gen,
        "boring_code_review": boring_code_review,
        "boring_perf_tips": boring_perf_tips,
        "boring_arch_check": boring_arch_check,
        "boring_doc_gen": boring_doc_gen,
        "boring_vibe_check": boring_vibe_check,
        "boring_impact_check": boring_impact_check,
        # V10.22 Intelligence Tools
        "boring_predict_errors": boring_predict_errors,
        "boring_health_score": boring_health_score,
        "boring_optimize_context": boring_optimize_context,
    }
